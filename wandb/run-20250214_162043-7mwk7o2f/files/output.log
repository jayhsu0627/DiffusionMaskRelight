INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 985
INFO:__main__:  Num Epochs = 100
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 16
INFO:__main__:  Gradient Accumulation steps = 16
INFO:__main__:  Total optimization steps = 6200
Steps:   0%|                                                                                                                                                                                                                              | 0/6200 [00:00<?, ?it/s]Traceback (most recent call last):
VAE precision: torch.float16
UNet precision: torch.float32
Trainable VAE precision: torch.float32
Optimizer dtype: torch.float32
pixel_values dtype: torch.float32
  File "/sdb5/DiffusionMaskRelight/train_svd_relight.py", line 1472, in <module>
    main()
  File "/sdb5/DiffusionMaskRelight/train_svd_relight.py", line 1195, in main
    shd_loss = (1-args.mse_weight)* lpips_vgg(recon_shd, shading_gt).mean() + args.mse_weight * F.mse_loss(recon_shd, shading_gt, reduction='mean')
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/lpips/lpips.py", line 119, in forward
    outs0, outs1 = self.net.forward(in0_input), self.net.forward(in1_input)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/lpips/pretrained_networks.py", line 121, in forward
    h = self.slice1(X)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
RuntimeError: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 12, 3, 256, 256]
