INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 217
INFO:__main__:  Num Epochs = 200
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 16
INFO:__main__:  Gradient Accumulation steps = 16
INFO:__main__:  Total optimization steps = 2800
Steps:   0%|                      | 3/2800 [01:13<14:51:09, 19.12s/it, lr=9e-7, step_loss=1.04]Traceback (most recent call last):
VAE precision: torch.float16
UNet precision: torch.float32
Optimizer dtype: torch.float32
pixel_values dtype: torch.float32
  File "/sdb5/DiffusionMaskRelight/train_svd_relight_syn.py", line 1501, in <module>
    main()
  File "/sdb5/DiffusionMaskRelight/train_svd_relight_syn.py", line 1232, in main
    enc_scb = tensor_to_vae_latent(scribbles_exp, vae)
  File "/sdb5/DiffusionMaskRelight/train_svd_relight_syn.py", line 257, in tensor_to_vae_latent
    torch.cuda.empty_cache()  # ðŸš€ Free GPU memory
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/cuda/memory.py", line 218, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
