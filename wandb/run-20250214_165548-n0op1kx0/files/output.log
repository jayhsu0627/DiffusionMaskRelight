INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 30
INFO:__main__:  Num Epochs = 100
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 16
INFO:__main__:  Gradient Accumulation steps = 16
INFO:__main__:  Total optimization steps = 200
Steps:   0%|â–‰                                                                                                                                                                                           | 1/200 [00:31<1:33:39, 28.24s/it, lr=6e-8, step_loss=1.41]Traceback (most recent call last):
VAE precision: torch.float16
UNet precision: torch.float32
Trainable VAE precision: torch.float32
Optimizer dtype: torch.float32
pixel_values dtype: torch.float32
  File "/sdb5/DiffusionMaskRelight/train_svd_relight.py", line 1472, in <module>
    main()
  File "/sdb5/DiffusionMaskRelight/train_svd_relight.py", line 1209, in main
    enc_shd = tensor_to_vae_latent(shading, vae)
  File "/sdb5/DiffusionMaskRelight/train_svd_relight.py", line 256, in tensor_to_vae_latent
    torch.cuda.empty_cache()  # ðŸš€ Free GPU memory
  File "/opt/conda/envs/DiffLight/lib/python3.10/site-packages/torch/cuda/memory.py", line 218, in empty_cache
    torch._C._cuda_emptyCache()
KeyboardInterrupt
